{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import math, re, os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from convert_to_tfrecords import *\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_filenames = \"/home/z3u5/Desktop/tfrecords/patches0.tfrecord\"\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_labeled_tfrecord , num_parallel_calls=AUTO)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_dataset(filenames):\n",
    "    dataset = load_dataset(filenames, labeled=True)\n",
    "    dataset = dataset.map(prepare_dataset)\n",
    "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(img1,img2,img3,height,width):\n",
    "    fraction = 0.8533333\n",
    "    img1 = tf.image.central_crop(img1, central_fraction = fraction)\n",
    "    img3 = tf.image.central_crop(img3, central_fraction = fraction)\n",
    "    return tf.concat([img1,img3],axis = -1),img2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes:\n",
      "(32, 128, 128, 6) (32, 150, 150, 3)\n",
      "(32, 128, 128, 6) (32, 150, 150, 3)\n",
      "(32, 128, 128, 6) (32, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shapes:\")\n",
    "for img1, img2 in get_training_dataset(training_filenames).take(3):\n",
    "    print(img1.numpy().shape, img2.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_examples = 2500\n",
    "steps_per_epochs = num_training_examples//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_module(x,filters,conv_filter_size,stride,padding='same'):\n",
    "    x = tf.keras.layers.Conv2D(filters,conv_filter_size,strides = stride,padding = padding,activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Conv2D(filters,conv_filter_size,strides = stride,padding = padding,activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Conv2D(filters,conv_filter_size,strides = stride,padding = padding,activation = 'relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_module(x,filters,conv_filter_size,stride,upsample_size = (2,2),padding='same'):\n",
    "    x = tf.keras.layers.UpSampling2D(size = upsample_size,interpolation = 'bilinear')(x)\n",
    "    x = tf.keras.layers.Conv2D(filters,conv_filter_size,strides = stride,padding = padding,activation = 'relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_kernel(x,kernel_dimension , conv_filter_size, stride, padding, upsample_size):\n",
    "    x = tf.keras.layers.Conv2D(filters = kernel_dimension,kernel_size = conv_filter_size, strides = stride, padding = padding, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Conv2D(filters = kernel_dimension,kernel_size = conv_filter_size, strides = stride, padding = padding, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Conv2D(filters = kernel_dimension,kernel_size = conv_filter_size, strides = stride, padding = padding, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.UpSampling2D(size = upsample_size,interpolation = 'bilinear')(x)\n",
    "    x = tf.keras.layers.Conv2D(filters = kernel_dimension,kernel_size = conv_filter_size, strides = stride, padding = padding, activation = 'relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units=32):\n",
    "        super(Linear, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# linear_layer = Linear(32)  # At instantiation, we don't know on what inputs this is going to get called\n",
    "# y = linear_layer(np.zeros(42).reshape((6,7)),|np.zeros(42).reshape((7,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class SeparableConvolutionSlow(tf.keras.layers.Layer):\n",
    "#     def __init__(self):\n",
    "#         super(SeparableConvolutionSlow, self).__init__()\n",
    "        \n",
    "\n",
    "#     def build(self, input_shape):\n",
    "        \n",
    "#         self.outputs = tf.Variable(initial_value=tf.zeros([BATCH_SIZE,128,128,3]),trainable=False)\n",
    "        \n",
    "    \n",
    "#     def call(self, im, vertical, horizontal):\n",
    "#         n_b = im.shape[0]\n",
    "#         n_channels = im.shape[-1]\n",
    "#         m = im.shape[1]\n",
    "#         m_out = m - 51 + 1\n",
    "        \n",
    "#         assert im.shape[1] == im.shape[2]\n",
    "#         assert vertical.shape[0] == horizontal.shape[0] == n_b\n",
    "#         assert vertical.shape[-1] == horizontal.shape[-1] == 51\n",
    "#         assert vertical.shape[1] == horizontal.shape[1] == vertical.shape[2] == horizontal.shape[2] == m_out\n",
    "\n",
    "#         self.outputs =  tf.Variable(lambda : tf.random.truncated_normal([BATCH_SIZE,128,128,3]),trainable = False)\n",
    "#         return _sep_conv_worker(im, horizontal, vertical,n_b, self.outputs)  \n",
    "    \n",
    "    \n",
    "    \n",
    "# def local_separable_conv_2d(im, horizontal, vertical, output=None):\n",
    "\n",
    "#     n_channels = im.shape[-1]\n",
    "#     m = im.shape[1]\n",
    "#     m_out = m - 51 + 1\n",
    "#     output = tf.Variable(lambda : tf.random.truncated_normal([m_out, m_out,n_channels]))\n",
    "#     for row in range(m_out):\n",
    "#         for col in range(m_out):\n",
    "#             sub_patch = im[row:row + 51, col:col + 51,:]\n",
    "# #             print(sub_patch.shape)\n",
    "#             local_horiz = tf.reshape(horizontal[row, col,:],[1,-1])\n",
    "# #             print(local_horiz.shape)\n",
    "#             local_vert = tf.reshape(vertical[row, col,:],[-1,1])\n",
    "# #             print(local_vert.shape)\n",
    "#             kernel = tf.math.multiply(local_horiz,local_vert)\n",
    "#             print(tf.reduce_sum(tf.reduce_sum((sub_patch * tf.expand_dims(kernel,-1)),axis = 0),axis = 0).shape)\n",
    "#             output[row, col,:].assign(tf.reduce_sum(tf.reduce_sum((sub_patch * tf.expand_dims(kernel,-1)),axis = 0),axis = 0))\n",
    "#             del local_horiz\n",
    "#             del local_vert\n",
    "#             del kernel\n",
    "#             del sub_patch\n",
    "            \n",
    "#     return output\n",
    "\n",
    "\n",
    "\n",
    "# def _sep_conv_worker(im, horizontal, vertical,batch_size, outputs):\n",
    "#     n_b = batch_size\n",
    "#     if n_b == None:\n",
    "#         n_b = 0\n",
    "#     for b in range(int(n_b)):\n",
    "#         local_separable_conv_2d(im[b], horizontal[b], vertical[b], output=outputs[b])\n",
    "        \n",
    "#     return outputs\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SeparableConvolutionSlow(tf.keras.layers.Layer):\n",
    "#     def __init__(self):\n",
    "#         super(SeparableConvolutionSlow, self).__init__()\n",
    "        \n",
    "\n",
    "#     def build(self, input_shape):\n",
    "        \n",
    "#         self.outputs = tf.Variable(initial_value=tf.zeros([BATCH_SIZE,128,128,3]),trainable=False)\n",
    "        \n",
    "    \n",
    "#     def call(self, im, vertical, horizontal):\n",
    "#         n_b = im.shape[0]\n",
    "#         n_channels = im.shape[-1]\n",
    "#         m = im.shape[1]\n",
    "#         m_out = m - 51 + 1\n",
    "        \n",
    "#         assert im.shape[1] == im.shape[2]\n",
    "#         assert vertical.shape[0] == horizontal.shape[0] == n_b\n",
    "#         assert vertical.shape[-1] == horizontal.shape[-1] == 51\n",
    "#         assert vertical.shape[1] == horizontal.shape[1] == vertical.shape[2] == horizontal.shape[2] == m_out\n",
    "\n",
    "#         return local_separable_conv_2d(im, horizontal, vertical)  \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# def local_separable_conv_2d(im, horizontal, vertical):\n",
    "#     output_list = []\n",
    "#     n_channels = im.shape[-1]\n",
    "#     m = im.shape[1]\n",
    "#     m_out = m - 51 + 1\n",
    "#     for row in range(m_out):\n",
    "#         for col in range(m_out):\n",
    "#             sub_patch = im[:,row:row + 51, col:col + 51,:]\n",
    "# #             print(sub_patch.shape)\n",
    "#             local_horiz = tf.expand_dims(horizontal[:,row, col,:],-2)\n",
    "# #             print(local_horiz.shape)\n",
    "#             local_vert = tf.expand_dims(vertical[:,row, col,:],-1)\n",
    "# #             print(local_vert.shape)\n",
    "# #             kernel = tf.math.multiply(local_horiz,local_vert)\n",
    "#             print(tf.reduce_sum(tf.reduce_sum((sub_patch * tf.expand_dims(local_horiz*local_vert,-1)),axis = 1),axis = 1).shape)\n",
    "#             output_list.append(tf.reduce_sum(tf.reduce_sum((sub_patch * tf.expand_dims(local_horiz*local_vert,-1)),axis = 1),axis = 1))\n",
    "\n",
    "            \n",
    "#     return tf.reshape(tf.stack(output_list,axis = 1),(-1,128,128,3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConvolutionSlow(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SeparableConvolutionSlow, self).__init__()\n",
    "        \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.outputs = tf.Variable(initial_value=tf.zeros([BATCH_SIZE,128,128,3]),trainable=False)\n",
    "        \n",
    "    \n",
    "    def call(self, im, vertical, horizontal):\n",
    "        n_b = im.shape[0]\n",
    "        n_channels = im.shape[-1]\n",
    "        m = im.shape[1]\n",
    "        m_out = m - 51 + 1\n",
    "        \n",
    "        assert im.shape[1] == im.shape[2]\n",
    "        assert vertical.shape[0] == horizontal.shape[0] == n_b\n",
    "        assert vertical.shape[-1] == horizontal.shape[-1] == 51\n",
    "        assert vertical.shape[1] == horizontal.shape[1] == vertical.shape[2] == horizontal.shape[2] == m_out\n",
    "\n",
    "        return local_separable_conv_2d(im, horizontal, vertical)  \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "def local_separable_conv_2d(im, horizontal, vertical):\n",
    "    output_list = []\n",
    "    n_channels = im.shape[-1]\n",
    "    m = im.shape[1]\n",
    "    m_out = m - 51 + 1\n",
    "    image_patches = tf.reshape(tf.image.extract_patches(im,sizes = [1,51,51,3],strides = [1,1,1,1],rates = [1,1,1,1],padding = 'VALID'),(-1,128,128,51,51,3))\n",
    "    output_kernels = tf.expand_dims(tf.math.multiply(tf.expand_dims(horizontal,-2),tf.expand_dims(vertical,-1)),-1)\n",
    "    output_images = tf.reduce_sum(tf.reduce_sum(image_patches*output_kernels,axis = -2),axis = -2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     for row in range(m_out):\n",
    "#         for col in range(m_out):\n",
    "#             sub_patch = im[:,row:row + 51, col:col + 51,:]\n",
    "# #             print(sub_patch.shape)\n",
    "#             local_horiz = tf.expand_dims(horizontal[:,row, col,:],-2)\n",
    "# #             print(local_horiz.shape)\n",
    "#             local_vert = tf.expand_dims(vertical[:,row, col,:],-1)\n",
    "# #             print(local_vert.shape)\n",
    "# #             kernel = tf.math.multiply(local_horiz,local_vert)\n",
    "#             print(tf.reduce_sum(tf.reduce_sum((sub_patch * tf.expand_dims(local_horiz*local_vert,-1)),axis = 1),axis = 1).shape)\n",
    "#             output_list.append(tf.reduce_sum(tf.reduce_sum((sub_patch * tf.expand_dims(local_horiz*local_vert,-1)),axis = 1),axis = 1))\n",
    "\n",
    "            \n",
    "    return output_images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    " \n",
    "    \n",
    "    return tf.norm(tf.norm(y_true-y_pred, ord=1, axis=(1,2)),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape = (128,128,6)):\n",
    "    conv_filter_size = (3, 3)\n",
    "    stride = (1, 1)\n",
    "    padding = 'same'\n",
    "    upsample_size = (2,2)\n",
    "    kernel_dimension = 51\n",
    "    x_input = tf.keras.Input(input_shape)\n",
    "    x = x_input\n",
    "    pad_dimension = kernel_dimension//2\n",
    "    i1 = x[:,:,:,0:3]\n",
    "    i_out = i1\n",
    "    i2 = x[:,:,:,3:6]\n",
    "    i1 = tf.pad(i1,[[0,0],[pad_dimension,pad_dimension],[pad_dimension,pad_dimension],[0,0]])\n",
    "    i2 = tf.pad(i2,[[0,0],[pad_dimension,pad_dimension],[pad_dimension,pad_dimension],[0,0]])\n",
    "    AvgPooling = tf.keras.layers.AveragePooling2D()\n",
    "    \n",
    "    x = conv_module(x,32,conv_filter_size,stride,padding)\n",
    "    x = AvgPooling(x)\n",
    "    \n",
    "    \n",
    "    x_64 = conv_module(x,64,conv_filter_size,stride,padding)\n",
    "    x_128 = AvgPooling(x_64)\n",
    "    \n",
    "    \n",
    "    x_128 = conv_module(x_128,128,conv_filter_size,stride,padding)\n",
    "    x_256 = AvgPooling(x_128)\n",
    "    \n",
    "    x_256 = conv_module(x_256,256,conv_filter_size,stride,padding)\n",
    "    x_512 = AvgPooling(x_256)\n",
    "    \n",
    "    x_512 = conv_module(x_512,512,conv_filter_size,stride,padding)\n",
    "    x = AvgPooling(x_512)\n",
    "    \n",
    "    x = conv_module(x,512,conv_filter_size,stride,padding)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = upsample_module(x,512,conv_filter_size,stride,upsample_size,padding)\n",
    "    x += x_512\n",
    "    x = conv_module(x,256,conv_filter_size,stride,padding)\n",
    "    \n",
    "    x = upsample_module(x,256,conv_filter_size,stride,upsample_size,padding)\n",
    "    x += x_256\n",
    "    x = conv_module(x,128,conv_filter_size,stride,padding)\n",
    "\n",
    "    x = upsample_module(x,128,conv_filter_size,stride,upsample_size,padding)\n",
    "    x += x_128\n",
    "    x = conv_module(x,64,conv_filter_size,stride,padding)\n",
    "    \n",
    "    x = upsample_module(x,64,conv_filter_size,stride,upsample_size,padding)\n",
    "    x += x_64\n",
    "#     print(x)\n",
    "    \n",
    "    k1h = generating_kernel(x,kernel_dimension , conv_filter_size, stride, padding, upsample_size)\n",
    "    k1v = generating_kernel(x,kernel_dimension , conv_filter_size, stride, padding, upsample_size)\n",
    "    k2h = generating_kernel(x,kernel_dimension , conv_filter_size, stride, padding, upsample_size)\n",
    "    k2v = generating_kernel(x,kernel_dimension , conv_filter_size, stride, padding, upsample_size)\n",
    "    \n",
    "    \n",
    "    image_patches = tf.reshape(tf.image.extract_patches(i1,sizes = [1,51,51,3],strides = [1,1,1,1],rates = [1,1,1,1],padding = 'VALID'),(-1,128,128,51,51,3))\n",
    "#     output_kernels = tf.expand_dims(tf.math.multiply(tf.expand_dims(horizontal,-2),tf.expand_dims(vertical,-1)),-1)\n",
    "    output_images = tf.reduce_sum(tf.reduce_sum(image_patches*tf.expand_dims(horizontal,-2)*tf.expand_dims(vertical,-1)),-1),axis = -2),axis = -2)\n",
    "    \n",
    "    \n",
    "    return tf.keras.Model(inputs = x_input, outputs = i_out, name = 'IIASC')\n",
    "    \n",
    "#     x = self.conv32(x)\n",
    "#     x = self.pool(x)\n",
    "\n",
    "#     x64 = self.conv64(x)\n",
    "#     x128 = self.pool(x64)\n",
    "\n",
    "#     x128 = self.conv128(x128)\n",
    "#     x256 = self.pool(x128)\n",
    "\n",
    "#     x256 = self.conv256(x256)\n",
    "#     x512 = self.pool(x256)\n",
    "\n",
    "#     x512 = self.conv512(x512)\n",
    "#     x = self.pool(x512)\n",
    "\n",
    "#     x = self.conv512x512(x)\n",
    "\n",
    "#     # ------------ Expansion ------------\n",
    "\n",
    "#     x = self.upsamp512(x)\n",
    "#     x += x512\n",
    "#     x = self.upconv256(x)\n",
    "\n",
    "#     x = self.upsamp256(x)\n",
    "#     x += x256\n",
    "#     x = self.upconv128(x)\n",
    "\n",
    "#     x = self.upsamp128(x)\n",
    "#     x += x128\n",
    "#     x = self.upconv64(x)\n",
    "\n",
    "#     x = self.upsamp64(x)\n",
    "#     x += x64\n",
    "\n",
    "#     # ------------ Final branches ------------\n",
    "\n",
    "#     k2h = self.upconv51_1(x)\n",
    "\n",
    "#     k2v = self.upconv51_2(x)\n",
    "\n",
    "#     k1h = self.upconv51_3(x)\n",
    "\n",
    "#     k1v = self.upconv51_4(x)\n",
    "\n",
    "#     padded_i2 = self.pad(i2)\n",
    "#     padded_i1 = self.pad(i1)\n",
    "#     self.pool = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"IIASC\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 128, 128, 6) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 128, 128, 32) 1760        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 128, 128, 32) 9248        conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 128, 128, 32) 9248        conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo multiple             0           conv2d_190[0][0]                 \n",
      "                                                                 conv2d_193[0][0]                 \n",
      "                                                                 conv2d_196[0][0]                 \n",
      "                                                                 conv2d_199[0][0]                 \n",
      "                                                                 conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 64, 64, 64)   18496       average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 64, 64, 64)   36928       conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 64, 64, 64)   36928       conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 32, 32, 128)  73856       average_pooling2d_4[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 32, 32, 128)  147584      conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 32, 32, 128)  147584      conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 256)  295168      average_pooling2d_4[2][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 256)  590080      conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 256)  590080      conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 8, 8, 512)    1180160     average_pooling2d_4[3][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 8, 8, 512)    2359808     conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 8, 8, 512)    2359808     conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 4, 4, 512)    2359808     average_pooling2d_4[4][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 4, 4, 512)    2359808     conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 4, 4, 512)    2359808     conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_32 (UpSampling2D) (None, 8, 8, 512)    0           conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 8, 8, 512)    2359808     up_sampling2d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_16 (TensorFlo [(None, 8, 8, 512)]  0           conv2d_206[0][0]                 \n",
      "                                                                 conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 8, 8, 256)    1179904     tf_op_layer_AddV2_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 8, 8, 256)    590080      conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 8, 8, 256)    590080      conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_33 (UpSampling2D) (None, 16, 16, 256)  0           conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 16, 16, 256)  590080      up_sampling2d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_17 (TensorFlo [(None, 16, 16, 256) 0           conv2d_210[0][0]                 \n",
      "                                                                 conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 16, 16, 128)  295040      tf_op_layer_AddV2_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 16, 16, 128)  147584      conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 16, 16, 128)  147584      conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_34 (UpSampling2D) (None, 32, 32, 128)  0           conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 32, 32, 128)  147584      up_sampling2d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_18 (TensorFlo [(None, 32, 32, 128) 0           conv2d_214[0][0]                 \n",
      "                                                                 conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 32, 32, 64)   73792       tf_op_layer_AddV2_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 32, 32, 64)   36928       conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 32, 32, 64)   36928       conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_35 (UpSampling2D) (None, 64, 64, 64)   0           conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 64, 64, 64)   36928       up_sampling2d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_19 (TensorFlo [(None, 64, 64, 64)] 0           conv2d_218[0][0]                 \n",
      "                                                                 conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 64, 64, 51)   29427       tf_op_layer_AddV2_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 64, 64, 51)   29427       tf_op_layer_AddV2_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 64, 64, 51)   23460       conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 64, 64, 51)   23460       conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 64, 64, 51)   23460       conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 64, 64, 51)   23460       conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 128, 128, 3) 0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_36 (UpSampling2D) (None, 128, 128, 51) 0           conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_37 (UpSampling2D) (None, 128, 128, 51) 0           conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Pad_8 (TensorFlowOp [(None, 178, 178, 3) 0           tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 128, 128, 51) 23460       up_sampling2d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 128, 128, 51) 23460       up_sampling2d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_convolution_slow_4 (S (None, 128, 128, 3)  1572864     tf_op_layer_Pad_8[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 22,940,958\n",
      "Trainable params: 21,368,094\n",
      "Non-trainable params: 1,572,864\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"IIASC\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 128, 128, 6) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 128, 128, 32) 1760        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 128, 128, 32) 9248        conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 128, 128, 32) 9248        conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo multiple             0           conv2d_190[0][0]                 \n",
      "                                                                 conv2d_193[0][0]                 \n",
      "                                                                 conv2d_196[0][0]                 \n",
      "                                                                 conv2d_199[0][0]                 \n",
      "                                                                 conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 64, 64, 64)   18496       average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 64, 64, 64)   36928       conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 64, 64, 64)   36928       conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 32, 32, 128)  73856       average_pooling2d_4[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 32, 32, 128)  147584      conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 32, 32, 128)  147584      conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 256)  295168      average_pooling2d_4[2][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 256)  590080      conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 256)  590080      conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 8, 8, 512)    1180160     average_pooling2d_4[3][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 8, 8, 512)    2359808     conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 8, 8, 512)    2359808     conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 4, 4, 512)    2359808     average_pooling2d_4[4][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 4, 4, 512)    2359808     conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 4, 4, 512)    2359808     conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_32 (UpSampling2D) (None, 8, 8, 512)    0           conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 8, 8, 512)    2359808     up_sampling2d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_16 (TensorFlo [(None, 8, 8, 512)]  0           conv2d_206[0][0]                 \n",
      "                                                                 conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 8, 8, 256)    1179904     tf_op_layer_AddV2_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 8, 8, 256)    590080      conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 8, 8, 256)    590080      conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_33 (UpSampling2D) (None, 16, 16, 256)  0           conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 16, 16, 256)  590080      up_sampling2d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_17 (TensorFlo [(None, 16, 16, 256) 0           conv2d_210[0][0]                 \n",
      "                                                                 conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 16, 16, 128)  295040      tf_op_layer_AddV2_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 16, 16, 128)  147584      conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 16, 16, 128)  147584      conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_34 (UpSampling2D) (None, 32, 32, 128)  0           conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 32, 32, 128)  147584      up_sampling2d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_18 (TensorFlo [(None, 32, 32, 128) 0           conv2d_214[0][0]                 \n",
      "                                                                 conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 32, 32, 64)   73792       tf_op_layer_AddV2_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 32, 32, 64)   36928       conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 32, 32, 64)   36928       conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_35 (UpSampling2D) (None, 64, 64, 64)   0           conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 64, 64, 64)   36928       up_sampling2d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_19 (TensorFlo [(None, 64, 64, 64)] 0           conv2d_218[0][0]                 \n",
      "                                                                 conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 64, 64, 51)   29427       tf_op_layer_AddV2_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 64, 64, 51)   29427       tf_op_layer_AddV2_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 64, 64, 51)   23460       conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 64, 64, 51)   23460       conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 64, 64, 51)   23460       conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 64, 64, 51)   23460       conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 128, 128, 3) 0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_36 (UpSampling2D) (None, 128, 128, 51) 0           conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_37 (UpSampling2D) (None, 128, 128, 51) 0           conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Pad_8 (TensorFlowOp [(None, 178, 178, 3) 0           tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 128, 128, 51) 23460       up_sampling2d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 128, 128, 51) 23460       up_sampling2d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_convolution_slow_4 (S (None, 128, 128, 3)  1572864     tf_op_layer_Pad_8[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 22,940,958\n",
      "Trainable params: 21,368,094\n",
      "Non-trainable params: 1,572,864\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# with strategy.scope():\n",
    "\n",
    "    \n",
    "#     model = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Conv2D(),\n",
    "#         tf.keras.layers.GlobalAveragePooling2D(),\n",
    "#         tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
    "#     ])\n",
    "        \n",
    "model.compile(\n",
    "    optimizer='adamax',\n",
    "    loss = custom_loss,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Only support ksizes across space.\n\t [[node IIASC/separable_convolution_slow_4/ExtractImagePatches (defined at <ipython-input-38-d64379cf053b>:32) ]] [Op:__inference_train_function_14709]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node IIASC/separable_convolution_slow_4/ExtractImagePatches:\n IIASC/tf_op_layer_Pad_8/Pad_8 (defined at <ipython-input-44-60b7f27fec54>:1)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-60b7f27fec54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_training_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m:  Only support ksizes across space.\n\t [[node IIASC/separable_convolution_slow_4/ExtractImagePatches (defined at <ipython-input-38-d64379cf053b>:32) ]] [Op:__inference_train_function_14709]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node IIASC/separable_convolution_slow_4/ExtractImagePatches:\n IIASC/tf_op_layer_Pad_8/Pad_8 (defined at <ipython-input-44-60b7f27fec54>:1)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(get_training_dataset(training_filenames), steps_per_epoch=steps_per_epochs, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'extract_image_patches'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d6dca7f09f31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_image_patches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'extract_image_patches'"
     ]
    }
   ],
   "source": [
    "tf.extract_image_patches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('my_env': conda)",
   "language": "python",
   "name": "python38164bitmyenvcondaf4f15e5c62a94a80a2358b33c250f3d1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
